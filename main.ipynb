{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4140,"sourceType":"datasetVersion","datasetId":2477},{"sourceId":21053618,"sourceType":"kernelVersion"}],"dockerImageVersionId":30824,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score, classification_report\nimport re\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\nfrom keras.layers import LayerNormalization\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:30:14.280305Z","iopub.execute_input":"2024-12-26T23:30:14.280634Z","iopub.status.idle":"2024-12-26T23:30:14.285603Z","shell.execute_reply.started":"2024-12-26T23:30:14.280605Z","shell.execute_reply":"2024-12-26T23:30:14.284533Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"Load the dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv', encoding='ISO-8859-1', header=None, names=['target', 'id', 'date', 'flag', 'user', 'text'])\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:30:18.445203Z","iopub.execute_input":"2024-12-26T23:30:18.445489Z","iopub.status.idle":"2024-12-26T23:30:21.846567Z","shell.execute_reply.started":"2024-12-26T23:30:18.445465Z","shell.execute_reply":"2024-12-26T23:30:21.845775Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"   target          id                          date      flag  \\\n0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n              user                                               text  \n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1    scotthamilton  is upset that he can't update his Facebook by ...  \n2         mattycus  @Kenichan I dived many times for the ball. Man...  \n3          ElleCTF    my whole body feels itchy and like its on fire   \n4           Karoli  @nationwideclass no, it's not behaving at all....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"df['target'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:30:22.826293Z","iopub.execute_input":"2024-12-26T23:30:22.826590Z","iopub.status.idle":"2024-12-26T23:30:22.841581Z","shell.execute_reply.started":"2024-12-26T23:30:22.826564Z","shell.execute_reply":"2024-12-26T23:30:22.840687Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"target\n0    800000\n4    800000\nName: count, dtype: int64"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"df = df[['text', 'target']]\ndf['target'] = df['target'].replace(4, 1)\ndf['target'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:30:25.517080Z","iopub.execute_input":"2024-12-26T23:30:25.517419Z","iopub.status.idle":"2024-12-26T23:30:25.569581Z","shell.execute_reply.started":"2024-12-26T23:30:25.517390Z","shell.execute_reply":"2024-12-26T23:30:25.568730Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"target\n0    800000\n1    800000\nName: count, dtype: int64"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"Take the first 5000 records of each class for simplicity","metadata":{}},{"cell_type":"code","source":"negative_samples = df[df['target'] == 0]\npositive_samples = df[df['target'] == 1]\n\ndf = pd.concat([negative_samples, positive_samples])\n\ndf['target'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:30:28.515325Z","iopub.execute_input":"2024-12-26T23:30:28.515641Z","iopub.status.idle":"2024-12-26T23:30:28.645788Z","shell.execute_reply.started":"2024-12-26T23:30:28.515614Z","shell.execute_reply":"2024-12-26T23:30:28.644975Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"target\n0    800000\n1    800000\nName: count, dtype: int64"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:30:31.289075Z","iopub.execute_input":"2024-12-26T23:30:31.289415Z","iopub.status.idle":"2024-12-26T23:30:31.378166Z","shell.execute_reply.started":"2024-12-26T23:30:31.289385Z","shell.execute_reply":"2024-12-26T23:30:31.377177Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 1600000 entries, 0 to 1599999\nData columns (total 2 columns):\n #   Column  Non-Null Count    Dtype \n---  ------  --------------    ----- \n 0   text    1600000 non-null  object\n 1   target  1600000 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 36.6+ MB\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:30:34.110001Z","iopub.execute_input":"2024-12-26T23:30:34.110336Z","iopub.status.idle":"2024-12-26T23:30:34.192277Z","shell.execute_reply.started":"2024-12-26T23:30:34.110306Z","shell.execute_reply":"2024-12-26T23:30:34.191427Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"text      0\ntarget    0\ndtype: int64"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\n\nnltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:30:36.761182Z","iopub.execute_input":"2024-12-26T23:30:36.761463Z","iopub.status.idle":"2024-12-26T23:30:36.823340Z","shell.execute_reply.started":"2024-12-26T23:30:36.761441Z","shell.execute_reply":"2024-12-26T23:30:36.822651Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    text = re.sub(r'@\\w+', '', text)  # Remove @ symbol and the usernames\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Remove links\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n    stop_words = set(stopwords.words('english'))\n    text = \" \".join([word for word in text.split() if word not in stop_words]) # Remove stopwords\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:30:39.855906Z","iopub.execute_input":"2024-12-26T23:30:39.856241Z","iopub.status.idle":"2024-12-26T23:30:39.861468Z","shell.execute_reply.started":"2024-12-26T23:30:39.856212Z","shell.execute_reply":"2024-12-26T23:30:39.859905Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"df['text'] = df['text'].apply(clean_text)\n\n\ndf['text'].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:30:42.644038Z","iopub.execute_input":"2024-12-26T23:30:42.644375Z","iopub.status.idle":"2024-12-26T23:33:58.553218Z","shell.execute_reply.started":"2024-12-26T23:30:42.644347Z","shell.execute_reply":"2024-12-26T23:33:58.552145Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"0        thats bummer shoulda got david carr third day\n1    upset cant update facebook texting might cry r...\n2    dived many times ball managed save 50 rest go ...\n3                     whole body feels itchy like fire\n4                             behaving im mad cant see\nName: text, dtype: object"},"metadata":{}}],"execution_count":47},{"cell_type":"markdown","source":"Split data into train and test","metadata":{}},{"cell_type":"code","source":"X = df['text']\ny = df['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:35:18.858263Z","iopub.execute_input":"2024-12-26T23:35:18.858721Z","iopub.status.idle":"2024-12-26T23:35:19.219954Z","shell.execute_reply.started":"2024-12-26T23:35:18.858679Z","shell.execute_reply":"2024-12-26T23:35:19.218957Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"TF-IDF vectorization for text feature extraction","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\nX_train_tfidf = vectorizer.fit_transform(X_train).toarray()\nX_val_tfidf = vectorizer.transform(X_val).toarray()\nX_test_tfidf = vectorizer.transform(X_test).toarray()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:36:34.908484Z","iopub.execute_input":"2024-12-26T23:36:34.908793Z","iopub.status.idle":"2024-12-26T23:37:05.061616Z","shell.execute_reply.started":"2024-12-26T23:36:34.908761Z","shell.execute_reply":"2024-12-26T23:37:05.060924Z"}},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":"Train the model","metadata":{}},{"cell_type":"code","source":"gnb = GaussianNB()\ngnb.fit(X_train_tfidf, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:47:03.517392Z","iopub.execute_input":"2024-12-26T21:47:03.517844Z","iopub.status.idle":"2024-12-26T21:47:19.193232Z","shell.execute_reply.started":"2024-12-26T21:47:03.517808Z","shell.execute_reply":"2024-12-26T21:47:19.192277Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"GaussianNB()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"Test the model","metadata":{}},{"cell_type":"code","source":"y_pred = gnb.predict(X_test_tfidf)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Test Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:47:20.925219Z","iopub.execute_input":"2024-12-26T21:47:20.925536Z","iopub.status.idle":"2024-12-26T21:47:24.426530Z","shell.execute_reply.started":"2024-12-26T21:47:20.925509Z","shell.execute_reply":"2024-12-26T21:47:24.425692Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.7029\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(\"Classification Report (GNB):\")\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:47:26.608216Z","iopub.execute_input":"2024-12-26T21:47:26.608502Z","iopub.status.idle":"2024-12-26T21:47:26.693646Z","shell.execute_reply.started":"2024-12-26T21:47:26.608482Z","shell.execute_reply":"2024-12-26T21:47:26.692828Z"}},"outputs":[{"name":"stdout","text":"Classification Report (GNB):\n              precision    recall  f1-score   support\n\n           0       0.74      0.63      0.68    119907\n           1       0.68      0.78      0.72    120093\n\n    accuracy                           0.70    240000\n   macro avg       0.71      0.70      0.70    240000\nweighted avg       0.71      0.70      0.70    240000\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Test the model with an external data","metadata":{}},{"cell_type":"code","source":"review = [\"Loved This Movie !!!!\"]\nreview_tfidf = vectorizer.transform(review).toarray()\nreview_pred = gnb.predict(review_tfidf)\n\nif review_pred[0] == 1:\n    print(\"Sentiment: Positive\")\nelse:\n    print(\"Sentiment: Negative\")\n","metadata":{"execution":{"iopub.status.busy":"2024-12-26T21:47:32.425213Z","iopub.execute_input":"2024-12-26T21:47:32.425504Z","iopub.status.idle":"2024-12-26T21:47:32.432572Z","shell.execute_reply.started":"2024-12-26T21:47:32.425482Z","shell.execute_reply":"2024-12-26T21:47:32.431692Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Sentiment: Positive\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"review = [\"The service was terrible, and I’ll never use it again.\"]\nreview_tfidf = vectorizer.transform(review).toarray()\nreview_pred = gnb.predict(review_tfidf)\n\nif review_pred[0] == 1:\n    print(\"Sentiment: Positive\")\nelse:\n    print(\"Sentiment: Negative\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:47:36.353931Z","iopub.execute_input":"2024-12-26T21:47:36.354239Z","iopub.status.idle":"2024-12-26T21:47:36.361408Z","shell.execute_reply.started":"2024-12-26T21:47:36.354215Z","shell.execute_reply":"2024-12-26T21:47:36.360684Z"}},"outputs":[{"name":"stdout","text":"Sentiment: Negative\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\ntokenizer.fit_on_texts(X_train)\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_val_seq = tokenizer.texts_to_sequences(X_val)\nX_test_seq = tokenizer.texts_to_sequences(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:37:58.660330Z","iopub.execute_input":"2024-12-26T23:37:58.660669Z","iopub.status.idle":"2024-12-26T23:38:26.457698Z","shell.execute_reply.started":"2024-12-26T23:37:58.660638Z","shell.execute_reply":"2024-12-26T23:38:26.457037Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"text_lengths = [len(seq) for seq in tokenizer.texts_to_sequences(X_train)]\n\nmax_len = max(text_lengths)  \nprint(f\"Max Length chosen: {max_len}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:38:30.660083Z","iopub.execute_input":"2024-12-26T23:38:30.660412Z","iopub.status.idle":"2024-12-26T23:38:42.143425Z","shell.execute_reply.started":"2024-12-26T23:38:30.660386Z","shell.execute_reply":"2024-12-26T23:38:42.142456Z"}},"outputs":[{"name":"stdout","text":"Max Length chosen: 35\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\nX_val_padded = pad_sequences(X_val_seq, maxlen=max_len, padding='post', truncating='post')\nX_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:48:24.571763Z","iopub.execute_input":"2024-12-26T21:48:24.572057Z","iopub.status.idle":"2024-12-26T21:48:27.586066Z","shell.execute_reply.started":"2024-12-26T21:48:24.572034Z","shell.execute_reply":"2024-12-26T21:48:27.585410Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"lstm_model = Sequential([\n    Embedding(input_dim=5000, output_dim=128, input_length=max_len),\n    LSTM(128, return_sequences=True),\n    LayerNormalization(),\n    Dropout(0.4),\n    LSTM(64),\n    LayerNormalization(),\n    Dropout(0.2),\n    Dense(1, activation='sigmoid')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:48:51.609589Z","iopub.execute_input":"2024-12-26T21:48:51.609887Z","iopub.status.idle":"2024-12-26T21:48:52.247063Z","shell.execute_reply.started":"2024-12-26T21:48:51.609864Z","shell.execute_reply":"2024-12-26T21:48:52.246422Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Define the callbacks\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',   \n    patience=3,               \n    restore_best_weights=True \n)\n\nmodel_checkpoint = ModelCheckpoint(\n    filepath='best_lstm_model.keras',  \n    monitor='val_accuracy',        \n    save_best_only=True,            \n    mode='max',                    \n    verbose=1                      \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:48:55.582435Z","iopub.execute_input":"2024-12-26T21:48:55.582746Z","iopub.status.idle":"2024-12-26T21:48:55.587126Z","shell.execute_reply.started":"2024-12-26T21:48:55.582718Z","shell.execute_reply":"2024-12-26T21:48:55.586016Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:48:59.388735Z","iopub.execute_input":"2024-12-26T21:48:59.389045Z","iopub.status.idle":"2024-12-26T21:48:59.407148Z","shell.execute_reply.started":"2024-12-26T21:48:59.389018Z","shell.execute_reply":"2024-12-26T21:48:59.406268Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"history = lstm_model.fit(\n    X_train_padded, y_train,\n    validation_data=(X_val_padded, y_val),\n    epochs=20,                     \n    batch_size=64,\n    callbacks=[early_stopping, model_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:49:04.732708Z","iopub.execute_input":"2024-12-26T21:49:04.733026Z","iopub.status.idle":"2024-12-26T22:04:52.284069Z","shell.execute_reply.started":"2024-12-26T21:49:04.732997Z","shell.execute_reply":"2024-12-26T22:04:52.283387Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m17498/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7454 - loss: 0.5090\nEpoch 1: val_accuracy improved from -inf to 0.78473, saving model to best_lstm_model.keras\n\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 9ms/step - accuracy: 0.7454 - loss: 0.5090 - val_accuracy: 0.7847 - val_loss: 0.4533\nEpoch 2/20\n\u001b[1m17494/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7880 - loss: 0.4475\nEpoch 2: val_accuracy improved from 0.78473 to 0.78957, saving model to best_lstm_model.keras\n\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 9ms/step - accuracy: 0.7880 - loss: 0.4475 - val_accuracy: 0.7896 - val_loss: 0.4449\nEpoch 3/20\n\u001b[1m17497/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7961 - loss: 0.4335\nEpoch 3: val_accuracy improved from 0.78957 to 0.79041, saving model to best_lstm_model.keras\n\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 9ms/step - accuracy: 0.7961 - loss: 0.4335 - val_accuracy: 0.7904 - val_loss: 0.4415\nEpoch 4/20\n\u001b[1m17494/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8024 - loss: 0.4225\nEpoch 4: val_accuracy did not improve from 0.79041\n\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 9ms/step - accuracy: 0.8024 - loss: 0.4225 - val_accuracy: 0.7901 - val_loss: 0.4440\nEpoch 5/20\n\u001b[1m17497/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8092 - loss: 0.4106\nEpoch 5: val_accuracy did not improve from 0.79041\n\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 9ms/step - accuracy: 0.8092 - loss: 0.4106 - val_accuracy: 0.7903 - val_loss: 0.4434\nEpoch 6/20\n\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8133 - loss: 0.4030\nEpoch 6: val_accuracy did not improve from 0.79041\n\u001b[1m17500/17500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 9ms/step - accuracy: 0.8133 - loss: 0.4030 - val_accuracy: 0.7900 - val_loss: 0.4499\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Evaluate LSTM\ny_pred_lstm = (lstm_model.predict(X_test_padded) > 0.5).astype('int32')\naccuracy_lstm = accuracy_score(y_test, y_pred_lstm)\nprint(f\"LSTM Test Accuracy: {accuracy_lstm:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T22:06:19.502606Z","iopub.execute_input":"2024-12-26T22:06:19.502917Z","iopub.status.idle":"2024-12-26T22:06:42.654393Z","shell.execute_reply.started":"2024-12-26T22:06:19.502895Z","shell.execute_reply":"2024-12-26T22:06:42.653481Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step\nLSTM Test Accuracy: 0.7899\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"print(\"Classification Report (LSTM):\")\nprint(classification_report(y_test, y_pred_lstm))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T22:07:03.629063Z","iopub.execute_input":"2024-12-26T22:07:03.629434Z","iopub.status.idle":"2024-12-26T22:07:03.711555Z","shell.execute_reply.started":"2024-12-26T22:07:03.629405Z","shell.execute_reply":"2024-12-26T22:07:03.710533Z"}},"outputs":[{"name":"stdout","text":"Classification Report (LSTM):\n              precision    recall  f1-score   support\n\n           0       0.78      0.81      0.79    119907\n           1       0.80      0.77      0.79    120093\n\n    accuracy                           0.79    240000\n   macro avg       0.79      0.79      0.79    240000\nweighted avg       0.79      0.79      0.79    240000\n\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Input review\nreview = [\"Loved This Movie !!!!\"]\n\n# Preprocess the review\nreview_seq = tokenizer.texts_to_sequences(review)  # Tokenize the review\nreview_padded = pad_sequences(review_seq, maxlen=max_len, padding='post', truncating='post')  # Pad the sequence\n\n# Predict sentiment using the LSTM model\nreview_pred = lstm_model.predict(review_padded)\n\n# Interpret the result\nif review_pred[0] > 0.5:\n    print(\"Sentiment: Positive\")\nelse:\n    print(\"Sentiment: Negative\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T22:07:13.694242Z","iopub.execute_input":"2024-12-26T22:07:13.694558Z","iopub.status.idle":"2024-12-26T22:07:13.957892Z","shell.execute_reply.started":"2024-12-26T22:07:13.694530Z","shell.execute_reply":"2024-12-26T22:07:13.957198Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\nSentiment: Positive\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Input review\nreview = [\"I absolutely love this place; it’s the best experience I’ve ever had!\" ]\n\n# Preprocess the review\nreview_seq = tokenizer.texts_to_sequences(review)  # Tokenize the review\nreview_padded = pad_sequences(review_seq, maxlen=max_len, padding='post', truncating='post')  # Pad the sequence\n\n# Predict sentiment using the LSTM model\nreview_pred = lstm_model.predict(review_padded)\n\n# Interpret the result\nif review_pred[0] > 0.5:\n    print(\"Sentiment: Positive\")\nelse:\n    print(\"Sentiment: Negative\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T22:07:20.279619Z","iopub.execute_input":"2024-12-26T22:07:20.279919Z","iopub.status.idle":"2024-12-26T22:07:20.341253Z","shell.execute_reply.started":"2024-12-26T22:07:20.279896Z","shell.execute_reply":"2024-12-26T22:07:20.340405Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\nSentiment: Positive\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Calculate text lengths\ntext_lengths = [len(seq) for seq in tokenizer.texts_to_sequences(X_train)]\n\n# Choose a max length based on a percentile\nmax_len = int(np.percentile(text_lengths, 95))  # Covers 95% of the data\nprint(f\"Max Length chosen: {max_len}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-26T23:38:57.677176Z","iopub.execute_input":"2024-12-26T23:38:57.677459Z","iopub.status.idle":"2024-12-26T23:39:09.355486Z","shell.execute_reply.started":"2024-12-26T23:38:57.677438Z","shell.execute_reply":"2024-12-26T23:39:09.354646Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Max Length chosen: 15\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"from transformers import BertTokenizer\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch\n\n# Initialize tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\nmax_len = 15\n\n# Tokenize the training data\ntrain_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=max_len, return_tensors=\"tf\")\nval_encodings = tokenizer(list(X_val), truncation=True, padding=True, max_length=max_len, return_tensors=\"tf\")\ntest_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=max_len, return_tensors=\"tf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:42:25.448684Z","iopub.execute_input":"2024-12-26T23:42:25.448974Z","iopub.status.idle":"2024-12-26T23:48:01.801573Z","shell.execute_reply.started":"2024-12-26T23:42:25.448951Z","shell.execute_reply":"2024-12-26T23:48:01.800855Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"y_train = y_train.reset_index(drop=True)\ny_val = y_val.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)\n\n# Convert the labels to tensor format\ntrain_labels = torch.tensor(y_train)\nval_labels = torch.tensor(y_val)\ntest_labels = torch.tensor(y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:48:58.369752Z","iopub.execute_input":"2024-12-26T23:48:58.370067Z","iopub.status.idle":"2024-12-26T23:49:02.581311Z","shell.execute_reply.started":"2024-12-26T23:48:58.370040Z","shell.execute_reply":"2024-12-26T23:49:02.580400Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"# Convert TensorFlow tensors to PyTorch tensors\ntrain_input_ids = torch.tensor(train_encodings['input_ids'].numpy()) \ntrain_attention_mask = torch.tensor(train_encodings['attention_mask'].numpy())\nval_input_ids = torch.tensor(val_encodings['input_ids'].numpy())\nval_attention_mask = torch.tensor(val_encodings['attention_mask'].numpy())\ntest_input_ids = torch.tensor(test_encodings['input_ids'].numpy())\ntest_attention_mask = torch.tensor(test_encodings['attention_mask'].numpy())\n\n# Create TensorDatasets using PyTorch tensors\ntrain_dataset = TensorDataset(train_input_ids, train_attention_mask, train_labels)\nval_dataset = TensorDataset(val_input_ids, val_attention_mask, val_labels)\ntest_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:49:05.544205Z","iopub.execute_input":"2024-12-26T23:49:05.544481Z","iopub.status.idle":"2024-12-26T23:49:05.687397Z","shell.execute_reply.started":"2024-12-26T23:49:05.544459Z","shell.execute_reply":"2024-12-26T23:49:05.686481Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# Create DataLoaders for batching\ntrain_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=128)\ntest_dataloader = DataLoader(test_dataset, batch_size=128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:49:09.660031Z","iopub.execute_input":"2024-12-26T23:49:09.660386Z","iopub.status.idle":"2024-12-26T23:49:09.664712Z","shell.execute_reply.started":"2024-12-26T23:49:09.660356Z","shell.execute_reply":"2024-12-26T23:49:09.663850Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\nfrom transformers import AdamW\n\n# Initialize the BERT model for sequence classification\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\n# Move the model to the second GPU (GPU 1)\ndevice = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)\n\n# Initialize the optimizer\noptimizer = AdamW(model.parameters(), lr=1e-5)\n\n# Optional: Use learning rate scheduler\nfrom transformers import get_linear_schedule_with_warmup\nnum_train_steps = len(train_dataloader) * 2\nnum_warmup_steps = 0\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_train_steps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:49:13.076784Z","iopub.execute_input":"2024-12-26T23:49:13.077062Z","iopub.status.idle":"2024-12-26T23:49:13.531607Z","shell.execute_reply.started":"2024-12-26T23:49:13.077038Z","shell.execute_reply":"2024-12-26T23:49:13.530540Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"from torch.nn import functional as F\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm  \n\n# Training parameters\nnum_epochs = 2\n\n# Training loop\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n\n    # Set the model to train mode\n    model.train()\n    total_train_loss = 0\n\n    # Use tqdm for training progress\n    train_progress = tqdm(train_dataloader, desc=\"Training\", leave=False)\n    for batch in train_progress:\n        input_ids, attention_mask, labels = [item.to(device) for item in batch]\n\n        # Forward pass\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n\n        # Backward pass\n        total_train_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n\n        # Update progress bar with the current loss\n        train_progress.set_postfix(loss=loss.item())\n\n    # Print average training loss for this epoch\n    avg_train_loss = total_train_loss / len(train_dataloader)\n    print(f\"Training loss: {avg_train_loss:.4f}\")\n\n    # Validation phase\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    # Use tqdm for validation progress\n    val_progress = tqdm(val_dataloader, desc=\"Validation\", leave=False)\n    with torch.no_grad():\n        for batch in val_progress:\n            input_ids, attention_mask, labels = [item.to(device) for item in batch]\n\n            # Forward pass\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n\n            # Get predictions\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            labels = labels.cpu().numpy()\n\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n\n    # Calculate validation accuracy\n    val_accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Validation Accuracy: {val_accuracy:.4f}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:49:18.484289Z","iopub.execute_input":"2024-12-26T23:49:18.484605Z","iopub.status.idle":"2024-12-27T00:47:44.278015Z","shell.execute_reply.started":"2024-12-26T23:49:18.484576Z","shell.execute_reply":"2024-12-27T00:47:44.277176Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.4460\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.8042\n\nEpoch 2/2\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.4067\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.8083\n\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"# Testing the model\nmodel.eval() \ntest_preds = []\ntest_labels = []\n\nwith torch.no_grad():\n    for batch in test_dataloader:\n        input_ids, attention_mask, labels = [item.to(device) for item in batch]\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        test_preds.extend(preds)\n        test_labels.extend(labels.cpu().numpy())\n\n# Test accuracy\ntest_accuracy = accuracy_score(test_labels, test_preds)\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T00:47:53.220762Z","iopub.execute_input":"2024-12-27T00:47:53.221455Z","iopub.status.idle":"2024-12-27T00:49:35.311986Z","shell.execute_reply.started":"2024-12-27T00:47:53.221429Z","shell.execute_reply":"2024-12-27T00:49:35.311035Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.8082\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"print(\"Classification Report (Bert):\")\nprint(classification_report(test_labels, test_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T00:49:42.472448Z","iopub.execute_input":"2024-12-27T00:49:42.472775Z","iopub.status.idle":"2024-12-27T00:49:42.616636Z","shell.execute_reply.started":"2024-12-27T00:49:42.472746Z","shell.execute_reply":"2024-12-27T00:49:42.615814Z"}},"outputs":[{"name":"stdout","text":"Classification Report (Bert):\n              precision    recall  f1-score   support\n\n           0       0.80      0.81      0.81    119907\n           1       0.81      0.80      0.81    120093\n\n    accuracy                           0.81    240000\n   macro avg       0.81      0.81      0.81    240000\nweighted avg       0.81      0.81      0.81    240000\n\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"# Input review\nreview = [\"Loved This Movie !!!!\"]\n\n# Preprocess the review using the BERT tokenizer\nencoded_review = tokenizer(\n    review,\n    truncation=True,\n    padding=True,\n    max_length=max_len,\n    return_tensors=\"pt\"  # Return PyTorch tensors\n)\n\n# Move the input tensors to the device (e.g., GPU 1)\ninput_ids = encoded_review['input_ids'].to(device)\nattention_mask = encoded_review['attention_mask'].to(device)\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Perform prediction\nwith torch.no_grad():\n    outputs = model(input_ids, attention_mask=attention_mask)\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=1).cpu().numpy()\n\n# Interpret the result\nif predictions[0] == 1:\n    print(\"Sentiment: Positive\")\nelse:\n    print(\"Sentiment: Negative\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T00:49:47.622409Z","iopub.execute_input":"2024-12-27T00:49:47.622701Z","iopub.status.idle":"2024-12-27T00:49:47.650712Z","shell.execute_reply.started":"2024-12-27T00:49:47.622677Z","shell.execute_reply":"2024-12-27T00:49:47.649984Z"}},"outputs":[{"name":"stdout","text":"Sentiment: Positive\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"# Input review\nreview = [\"This product works perfectly, and I couldn't be happier!\"]\n\n# Preprocess the review using the BERT tokenizer\nencoded_review = tokenizer(\n    review,\n    truncation=True,\n    padding=True,\n    max_length=max_len,\n    return_tensors=\"pt\"  # Return PyTorch tensors\n)\n\n# Move the input tensors to the device (e.g., GPU 1)\ninput_ids = encoded_review['input_ids'].to(device)\nattention_mask = encoded_review['attention_mask'].to(device)\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Perform prediction\nwith torch.no_grad():\n    outputs = model(input_ids, attention_mask=attention_mask)\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=1).cpu().numpy()\n\n# Interpret the result\nif predictions[0] == 1:\n    print(\"Sentiment: Positive\")\nelse:\n    print(\"Sentiment: Negative\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T00:49:53.762395Z","iopub.execute_input":"2024-12-27T00:49:53.762691Z","iopub.status.idle":"2024-12-27T00:49:53.779516Z","shell.execute_reply.started":"2024-12-27T00:49:53.762666Z","shell.execute_reply":"2024-12-27T00:49:53.778642Z"}},"outputs":[{"name":"stdout","text":"Sentiment: Positive\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"# Input review\nreview = [\"The product broke after one use—such a waste of money.\"]\n\n# Preprocess the review using the BERT tokenizer\nencoded_review = tokenizer(\n    review,\n    truncation=True,\n    padding=True,\n    max_length=max_len,\n    return_tensors=\"pt\"  # Return PyTorch tensors\n)\n\n# Move the input tensors to the device (e.g., GPU 1)\ninput_ids = encoded_review['input_ids'].to(device)\nattention_mask = encoded_review['attention_mask'].to(device)\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Perform prediction\nwith torch.no_grad():\n    outputs = model(input_ids, attention_mask=attention_mask)\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=1).cpu().numpy()\n\n# Interpret the result\nif predictions[0] == 1:\n    print(\"Sentiment: Positive\")\nelse:\n    print(\"Sentiment: Negative\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T00:52:14.759003Z","iopub.execute_input":"2024-12-27T00:52:14.759345Z","iopub.status.idle":"2024-12-27T00:52:14.776934Z","shell.execute_reply.started":"2024-12-27T00:52:14.759318Z","shell.execute_reply":"2024-12-27T00:52:14.776203Z"}},"outputs":[{"name":"stdout","text":"Sentiment: Negative\n","output_type":"stream"}],"execution_count":67}]}